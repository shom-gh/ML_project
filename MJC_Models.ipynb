{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr, RandomForestRegressor as rfr, ExtraTreesRegressor as etr\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bb1d365c21cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loading train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./final_train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#loading test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./final_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/Kenneth S. Hansen/Dropbox/MSc Business Intelligence/Kaggle/y.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#loading train\n",
    "df_train=pd.read_csv('./final_train.csv')\n",
    "#loading test\n",
    "df_test=pd.read_csv('./final_test.csv')\n",
    "y = pd.read_csv('/Users/Kenneth S. Hansen/Dropbox/MSc Business Intelligence/Kaggle/y.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1\n",
       "0           \n",
       "0  12.247694\n",
       "1  12.109011\n",
       "2  12.317167\n",
       "3  11.849398\n",
       "4  12.429216"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y))\n",
    "len(df_train)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Setting index as ID columns\n",
    "df_test.set_index(['Id'], inplace = True)\n",
    "df_train.set_index(['Id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Setting y and x to begin running models\n",
    "Y_vals = pd.DataFrame(df_train['SalePrice']).copy()\n",
    "Y_vals = np.ravel(Y_vals)\n",
    "df_test.drop(['Unnamed: 0', 'SalePrice'],inplace=True, axis =1)\n",
    "df_train.drop(['Unnamed: 0', 'SalePrice'],inplace=True, axis =1)\n",
    "X_train=df_train.copy()\n",
    "X_test=df_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.19 s, sys: 295 ms, total: 8.48 s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LassoCV(alphas=None, copy_X=True, cv=None, eps=0.0001, fit_intercept=True,\n",
       "    max_iter=10000, n_alphas=100, n_jobs=1, normalize=True, positive=False,\n",
       "    precompute='auto', random_state=0, selection='cyclic', tol=0.0001,\n",
       "    verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'n_alphas': range(100, 1000, 100), 'random_state': [0], 'eps': [0.0001], 'normalize': [True]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Grid search for optimal lasso parameters\n",
    "grid_para_lasso = [{\n",
    "    \"n_alphas\": range(100,1000, 100),\n",
    "    \"random_state\": [0],\n",
    "    \"eps\" : [0.0001],\n",
    "    \"normalize\" : [True]\n",
    "}]\n",
    "grid_search_lasso = GridSearchCV(lasso_model, grid_para_lasso, cv=5, n_jobs=-1, verbose=1)\n",
    "%time grid_search_lasso.fit(X_train, Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-498-5b0eaac05c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_lasso' is not defined"
     ]
    }
   ],
   "source": [
    "print(grid_search_lasso.best_params_)\n",
    "print(grid_search_lasso.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90827657658135419"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = linear_model.LassoCV(random_state=0,n_alphas=1000, normalize=True, eps = 0.0001, max_iter=10000)\n",
    "mod = lasso_model.fit(X_train, Y_vals)\n",
    "mod.score(X_train, Y_vals)\n",
    "##score=0.93082405005697799\n",
    "#lasso_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 737 ms, total: 15.6 s\n",
      "Wall time: 4min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.0001,\n",
       "       fit_intercept=True, l1_ratio=0.5, max_iter=10000, n_alphas=1000,\n",
       "       n_jobs=1, normalize=True, positive=False, precompute='auto',\n",
       "       random_state=None, selection='cyclic', tol=0.0001, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'n_alphas': [1000], 'l1_ratio': array([ 0.1    ,  0.11837,  0.13673,  0.1551 ,  0.17347,  0.19184,\n",
       "        0.2102 ,  0.22857,  0.24694,  0.26531,  0.28367,  0.30204,\n",
       "        0.32041,  0.33878,  0.35714,  0.37551,  0.39388,  0.41224,\n",
       "        0.43061,  0.44898,  0.46735,  0.48571,  0.5040... 0.8898 ,  0.90816,  0.92653,  0.9449 ,  0.96327,\n",
       "        0.98163,  1.     ]), 'normalize': [True]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Grid search for optimal elastic parameters\n",
    "grid_para_elastic = [{\n",
    "    \"n_alphas\": [1000],\n",
    "    #\"alphas\": np.linspace(0,20,num=5),\n",
    "    \"l1_ratio\": np.linspace(0.1,1),\n",
    "    \"normalize\" : [True]\n",
    "}]\n",
    "grid_search_elastic = GridSearchCV(elastic_model, grid_para_elastic, cv=5, n_jobs=-1, verbose=1)\n",
    "%time grid_search_elastic.fit(X_train, Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.41224489795918373, 'n_alphas': 1000, 'normalize': True}\n",
      "0.870019350982\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_elastic.best_params_)\n",
    "print(grid_search_elastic.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905218654796\n",
      "0.122935442528\n"
     ]
    }
   ],
   "source": [
    "elastic_model = linear_model.ElasticNetCV(l1_ratio=0.41224489795918373,n_alphas=1000, normalize=True,eps = 0.0001,max_iter=10000).fit(X_train, np.ravel(Y_vals))\n",
    "mse = mean_squared_error(Y_vals, elastic_model.predict(X_train))\n",
    "print(elastic_model.score(X_train, np.ravel(Y_vals)))\n",
    "print(np.sqrt(mse))\n",
    "#1-0.112947265448\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr_model = ensemble.RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 125 candidates, totalling 1250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 out of 1250 | elapsed: 62.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 2min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'n_estimators': [1000], 'max_depth': range(1, 6), 'min_samples_leaf': range(1, 6), 'min_samples_split': array([ 2,  9, 16, 23, 30]), 'random_state': [0]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Grid search for optimal random tree parameters\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_para_rfr = [{\n",
    "    \"n_estimators\": [1000],\n",
    "    \"max_depth\": range(1, 6),\n",
    "    \"min_samples_leaf\": range(1,6),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=30, num=5, dtype=int),\n",
    "    \"random_state\": [0]\n",
    "}]\n",
    "\n",
    "grid_search_rfr = GridSearchCV(rfr_model, grid_para_rfr, cv=10, n_jobs=-1, verbose=1, scoring='neg_mean_squared_error')\n",
    "%time grid_search_rfr.fit(df_train, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 20.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'n_estimators': [1000], 'max_depth': range(8, 11), 'min_samples_leaf': range(2, 5), 'min_samples_split': array([ 2,  9, 16, 23, 30]), 'random_state': [0]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Grid search for optimal random tree parameters\n",
    "#Agreesive\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_para_rfr = [{\n",
    "    \"n_estimators\": [1000],\n",
    "    \"max_depth\": range(7,9),\n",
    "    \"min_samples_leaf\": range(2, 5),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=30, num=5, dtype=int),\n",
    "    \"random_state\": [0]\n",
    "}]\n",
    "\n",
    "grid_search_rfr = GridSearchCV(rfr_model, grid_para_rfr, cv=5, n_jobs=-1, verbose=1)\n",
    "%time grid_search_rfr.fit(df_train, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 1000, 'random_state': 0}\n",
      "-0.000193868552163\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rfr.best_params_)\n",
    "print(grid_search_rfr.best_score_)\n",
    "#0.88759734575697047\n",
    "#{'max_depth': 9,\n",
    "# 'min_samples_leaf': 1,\n",
    "# 'min_samples_split': 2,\n",
    "# 'n_estimators': 1000,\n",
    "# 'random_state': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927213532396\n",
      "0.853760776452\n"
     ]
    }
   ],
   "source": [
    "rfr_model = rfr(random_state=0, min_samples_leaf = 2, min_samples_split =2,\n",
    "        n_estimators=1000, max_depth=9,  max_features='sqrt', oob_score=True).fit(X_train, np.ravel(Y_vals))\n",
    "print(rfr_model.score(X_train, np.ravel(Y_vals)))\n",
    "print(rfr_model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Random Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'etr_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-69dd81ad8b43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;34m\"random_state\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m }]\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgrid_search_etr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metr_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_para_etr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time grid_search_etr.fit(df_train, np.ravel(y))'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'etr_model' is not defined"
     ]
    }
   ],
   "source": [
    "##Grid search for extra random tree parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_para_etr = [{\n",
    "    \"n_estimators\": [1000],\n",
    "    \"max_depth\": range(1,10),\n",
    "    \"min_samples_leaf\": range(1, 5),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=30, num=5, dtype=int),\n",
    "    \"random_state\": [0]\n",
    "}]\n",
    "grid_search_etr = GridSearchCV(etr_model, grid_para_etr, cv=5, n_jobs=-1, verbose=1)\n",
    "%time grid_search_etr.fit(df_train, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000, 'random_state': 0}\n",
      "0.809695308898\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_etr.best_params_)\n",
    "print(grid_search_etr.best_score_)\n",
    "#{'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000, 'random_state': 0}\n",
    "#0.81466266301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899224010175\n",
      "0.811302222087\n"
     ]
    }
   ],
   "source": [
    "etr_model = etr(random_state=0,min_samples_split=2,\n",
    "        n_estimators=1000, max_depth=9, min_samples_leaf= 1, max_features='sqrt', bootstrap=True,oob_score=True).fit(X_train,Y_vals)\n",
    "print(etr_model.score(X_train, Y_vals))\n",
    "print(etr_model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid Search for XGB -- Optimized via Ilyas Bayesion Optimizer instead\n",
    "grid_para_xgb = [{\n",
    "    'max_depth': [3,4,5,6,7],\n",
    "    'learning_rate': [.001, .01, .1],\n",
    "    'n_estimators': [200],\n",
    "    'gamma': [0.1],\n",
    "    'reg_alpha': [.25, .5, .75],\n",
    "    'reg_lambda': [.25, .5, .75],\n",
    "    'subsample': [.3 ,.5,.7,.9],\n",
    "    'colsample_bytree': [.4,.5,.6],\n",
    "    'min_child_weight': [.3, .6, .9]\n",
    "}]\n",
    "grid_search_xgb = GridSearchCV(xgb_model, grid_para_etr, cv=5, n_jobs=-1, verbose=1)\n",
    "%time grid_search_xgb.fit(X_train, Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0, learning_rate=0.05, max_delta_step=0, max_depth=20,\n",
       "       min_child_weight=0.1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=1, silent=False, subsample=1)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "                 colsample_bytree=1,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.05,\n",
    "                 max_depth=20,\n",
    "                 min_child_weight=0.1,\n",
    "                 n_estimators=1000,                                                                  \n",
    "                 reg_alpha=0,\n",
    "                 reg_lambda=1,\n",
    "                 subsample=1,\n",
    "                 seed=1,\n",
    "                 silent=False)\n",
    "\n",
    "xgb_model.fit(X_train, Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999792129154841"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.score(X_train, Y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "       boosting_type='gbdt', colsample_bytree=1.0, feature_fraction=0.2319,\n",
       "       feature_fraction_seed=9, learning_rate=0.05, max_bin=55,\n",
       "       max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
       "       min_data_in_leaf=6, min_split_gain=0.0, min_sum_hessian_in_leaf=11,\n",
       "       n_estimators=720, n_jobs=-1, num_leaves=5, objective='regression',\n",
       "       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Should tune this algorithm, but not sure what any of the parameters do\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "lgb_model.fit(X_train,Y_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96393645930842231"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.score(X_train, Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 4\n",
    "\n",
    "scorer = make_scorer(mean_squared_error,greater_is_better = False)\n",
    "def rmse_CV_train(model):\n",
    "    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(X_train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model,X_train,Y_vals,scoring =\"neg_mean_squared_error\",cv=kf, n_jobs=-1, verbose=1))\n",
    "    return (rmse)\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.log(y), np.log(y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for LassoCV:  0.0101191420426\n",
      "rmse for Elastic:  0.0102803446154\n",
      "rmse for XGBRegr:  4.78871005635e-05\n",
      "rmse for RandomF:  0.00908996582226\n",
      "rmse for ExtraTr:  0.0106191419038\n",
      "rmse for LGBMReg:  0.00640292114589\n"
     ]
    }
   ],
   "source": [
    "models = [lasso_model, elastic_model, xgb_model, rfr_model, etr_model, lgb_model]\n",
    "for i in models:\n",
    "    score = rmsle(Y_vals, i.predict(X_train))\n",
    "    print('rmse for '+str(i)[0:7]+ \": \",score)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE Score on each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean/std for LassoCV:  0.144388099798 0.0231283159032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   11.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean/std for Elastic:  0.142590646106 0.0197249454264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    5.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean/std for RandomF:  0.155135199282 0.0138732019442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean/std for ExtraTr:  0.174802628431 0.0132328851953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean/std for LGBMReg:  0.124189119792 0.0132627221085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    3.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "models = [lasso_model, elastic_model, rfr_model, etr_model, lgb_model]\n",
    "for i in models:\n",
    "    score = rmse_CV_train(i)\n",
    "    print('rmse mean/std for '+str(i)[0:7]+ \": \",score.mean(), score.std())\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in models:\n",
    "    results=round(pd.DataFrame(np.exp(i.predict(X_test))),3)\n",
    "    results.columns=['SalePrice']\n",
    "    results.set_index(df_test.index, inplace=True)\n",
    "    results.to_csv('output_'+str(i)[0:7]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_etr=pd.read_csv('./output_ExtraTr.csv', index_col='Id')\n",
    "df_rfr=pd.read_csv('./output_RandomF.csv', index_col='Id')\n",
    "df_lasso=pd.read_csv('./output_LassoCV.csv', index_col='Id')\n",
    "df_elastic=pd.read_csv('./output_Elastic.csv', index_col='Id')\n",
    "df_xgb=pd.read_csv('./output_XGBRegr.csv', index_col='Id')\n",
    "df_lgb=pd.read_csv('./output_LGBMReg.csv', index_col='Id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaged Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>123845.698729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>156090.811958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>184959.109250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>192666.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>193633.896208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SalePrice\n",
       "Id                 \n",
       "1461  123845.698729\n",
       "1462  156090.811958\n",
       "1463  184959.109250\n",
       "1464  192666.678500\n",
       "1465  193633.896208"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average = (df_rfr+df_lasso+df_elastic+df_etr+df_xgb+df_lgb)/6\n",
    "df_average.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_average.to_csv('ALL_average.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (elastic_model, rfr_model, etr_model),\n",
    "                                                 meta_model = lasso_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingAveragedModels(base_models=(ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.0001,\n",
       "       fit_intercept=True, l1_ratio=0.41224489795918373, max_iter=10000,\n",
       "       n_alphas=1000, n_jobs=1, normalize=True, positive=False,\n",
       "       precompute='auto', random_state=None, selection='cyclic',\n",
       "       tol=0.0001, verbos...n_estimators=1000, n_jobs=1,\n",
       "          oob_score=True, random_state=0, verbose=0, warm_start=False)),\n",
       "            meta_model=LassoCV(alphas=None, copy_X=True, cv=None, eps=0.0001, fit_intercept=True,\n",
       "    max_iter=10000, n_alphas=1000, n_jobs=1, normalize=True,\n",
       "    positive=False, precompute='auto', random_state=0, selection='cyclic',\n",
       "    tol=0.0001, verbose=False),\n",
       "            n_folds=5)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_averaged_models.fit(X_train.values, Y_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_pred = np.exp(stacked_averaged_models.predict(X_test.values))\n",
    "xgb_pred=np.exp(xgb_model.predict(X_test))\n",
    "lgb_pred=np.exp(lgb_model.predict(X_test))\n",
    "ensemble= stacked_pred*0.7 + xgb_pred *0.15 + lgb_pred*0.15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['SalePrice'] = np.round(ensemble,3)\n",
    "sub.set_index(df_test.index, inplace=True)\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_results=round(pd.DataFrame(np.exp(stacked_averaged_models.predict(X_test.values))),3)\n",
    "stacked_results.columns=['SalePrice']\n",
    "stacked_results.set_index(df_test.index, inplace=True)\n",
    "stacked_results.to_csv('stacked_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>121045.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>156573.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>185822.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>194683.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>194890.822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SalePrice\n",
       "Id              \n",
       "1461  121045.564\n",
       "1462  156573.502\n",
       "1463  185822.156\n",
       "1464  194683.013\n",
       "1465  194890.822"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stacking import stacking_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_model = lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: [rmsle]\n",
      "\n",
      "model 0: [LassoCV]\n",
      "    ----\n",
      "    MEAN:   [9.54594010]\n",
      "\n",
      "model 1: [ElasticNetCV]\n",
      "    ----\n",
      "    MEAN:   [9.54454733]\n",
      "\n",
      "model 2: [RandomForestRegressor]\n",
      "    ----\n",
      "    MEAN:   [9.54234048]\n",
      "\n",
      "model 3: [ExtraTreesRegressor]\n",
      "    ----\n",
      "    MEAN:   [9.54071370]\n",
      "\n",
      "model 4: [XGBRegressor]\n",
      "    ----\n",
      "    MEAN:   [9.54330248]\n",
      "\n",
      "model 5: [LGBMRegressor]\n",
      "    ----\n",
      "    MEAN:   [9.54483468]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacking_prediction = stacking_regression(models, meta_model, X_train, Y_vals, X_test,\n",
    "                              transform_pred = np.expm1, \n",
    "                               metric=rmsle, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125872.85637041,  150108.37848661,  178119.52683864, ...,\n",
       "        157552.96526958,  122456.88939299,  207038.61891604])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>125872.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>150108.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>178119.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>185903.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>184917.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>166934.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>160811.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>161489.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>168804.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>123967.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>188359.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>107570.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>109418.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>142584.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>118721.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>397231.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>252398.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>295064.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>275268.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>807912.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>348745.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>201375.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>164485.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>162494.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>172978.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>185232.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>348308.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>221799.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>196980.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>217726.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>99014.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>127935.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>86458.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>100959.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>91180.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>316693.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>280821.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>186102.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>144392.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>194258.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>151174.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>179038.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>175533.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>380595.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>442910.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>107162.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>185640.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>117645.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>129843.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>144489.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>97980.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>101077.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>141467.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>103099.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>97398.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>99635.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>104034.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>157552.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>122456.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>207038.619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SalePrice\n",
       "Id              \n",
       "1461  125872.856\n",
       "1462  150108.378\n",
       "1463  178119.527\n",
       "1464  185903.661\n",
       "1465  184917.702\n",
       "1466  166934.519\n",
       "1467  160811.239\n",
       "1468  161489.799\n",
       "1469  168804.036\n",
       "1470  123967.458\n",
       "1471  188359.308\n",
       "1472  107570.428\n",
       "1473  109418.363\n",
       "1474  142584.515\n",
       "1475  118721.556\n",
       "1476  397231.284\n",
       "1477  252398.753\n",
       "1478  295064.849\n",
       "1479  275268.975\n",
       "1480  807912.745\n",
       "1481  348745.492\n",
       "1482  201375.778\n",
       "1483  164485.437\n",
       "1484  162494.061\n",
       "1485  172978.944\n",
       "1486  185232.712\n",
       "1487  348308.333\n",
       "1488  221799.871\n",
       "1489  196980.493\n",
       "1490  217726.489\n",
       "...          ...\n",
       "2890   99014.868\n",
       "2891  127935.789\n",
       "2892   86458.045\n",
       "2893  100959.342\n",
       "2894   91180.649\n",
       "2895  316693.804\n",
       "2896  280821.529\n",
       "2897  186102.307\n",
       "2898  144392.517\n",
       "2899  194258.943\n",
       "2900  151174.974\n",
       "2901  179038.215\n",
       "2902  175533.171\n",
       "2903  380595.096\n",
       "2904  442910.402\n",
       "2905  107162.869\n",
       "2906  185640.899\n",
       "2907  117645.411\n",
       "2908  129843.842\n",
       "2909  144489.677\n",
       "2910   97980.986\n",
       "2911  101077.323\n",
       "2912  141467.881\n",
       "2913  103099.593\n",
       "2914   97398.311\n",
       "2915   99635.225\n",
       "2916  104034.261\n",
       "2917  157552.965\n",
       "2918  122456.889\n",
       "2919  207038.619\n",
       "\n",
       "[1459 rows x 1 columns]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp=round(pd.DataFrame(stacking_prediction),3)\n",
    "sp.set_index(df_test.index, inplace=True)\n",
    "sp.columns = ['SalePrice']\n",
    "sp.to_csv('ZYrun.csv')\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading train\n",
    "df_train=pd.read_csv('./final_train.csv')\n",
    "#loading test\n",
    "df_test=pd.read_csv('./final_test.csv')\n",
    "y = pd.read_csv('/Users/Kenneth S. Hansen/Dropbox/MSc Business Intelligence/Kaggle/y.csv', header=None, index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>TotLivArea</th>\n",
       "      <th>TotalBath</th>\n",
       "      <th>BsmtUnFinRatio</th>\n",
       "      <th>AreaPerCar</th>\n",
       "      <th>AvgRoomSize</th>\n",
       "      <th>GarageScore</th>\n",
       "      <th>OverallGrade</th>\n",
       "      <th>Overallscore</th>\n",
       "      <th>ExterGrade</th>\n",
       "      <th>AllPorchSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.175234</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>213.750000</td>\n",
       "      <td>AttchdAttchdAttchd</td>\n",
       "      <td>35</td>\n",
       "      <td>59850</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2524.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.225040</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>210.333333</td>\n",
       "      <td>AttchdAttchdAttchd</td>\n",
       "      <td>48</td>\n",
       "      <td>60576</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2706.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.471739</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>AttchdAttchdAttchd</td>\n",
       "      <td>35</td>\n",
       "      <td>62510</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>245.285714</td>\n",
       "      <td>DetchdDetchdDetchd</td>\n",
       "      <td>35</td>\n",
       "      <td>60095</td>\n",
       "      <td>9</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3343.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.427948</td>\n",
       "      <td>278.666667</td>\n",
       "      <td>244.222222</td>\n",
       "      <td>AttchdAttchdAttchd</td>\n",
       "      <td>40</td>\n",
       "      <td>87920</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr BldgType  BsmtCond  \\\n",
       "0       856       854          0      1             3     1Fam         3   \n",
       "1      1262         0          0      1             3     1Fam         3   \n",
       "2       920       866          0      1             3     1Fam         3   \n",
       "3       961       756          0      1             3     1Fam         4   \n",
       "4      1145      1053          0      1             4     1Fam         3   \n",
       "\n",
       "   BsmtExposure  BsmtFinSF1  BsmtFinSF2    ...      TotLivArea  TotalBath  \\\n",
       "0             1       706.0         0.0    ...          2566.0        3.5   \n",
       "1             4       978.0         0.0    ...          2524.0        2.5   \n",
       "2             2       486.0         0.0    ...          2706.0        3.5   \n",
       "3             1       216.0         0.0    ...          2473.0        2.0   \n",
       "4             3       655.0         0.0    ...          3343.0        3.5   \n",
       "\n",
       "   BsmtUnFinRatio  AreaPerCar  AvgRoomSize         GarageScore  OverallGrade  \\\n",
       "0        0.175234  274.000000   213.750000  AttchdAttchdAttchd            35   \n",
       "1        0.225040  230.000000   210.333333  AttchdAttchdAttchd            48   \n",
       "2        0.471739  304.000000   297.666667  AttchdAttchdAttchd            35   \n",
       "3        0.714286  214.000000   245.285714  DetchdDetchdDetchd            35   \n",
       "4        0.427948  278.666667   244.222222  AttchdAttchdAttchd            40   \n",
       "\n",
       "  Overallscore ExterGrade AllPorchSF  \n",
       "0        59850         12         61  \n",
       "1        60576          9          0  \n",
       "2        62510         12         42  \n",
       "3        60095          9        307  \n",
       "4        87920         12         84  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/Kenneth S. Hansen/Dropbox/MSc Business Intelligence/Kaggle/df_all.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.special import boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = list(df.select_dtypes(exclude = ['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 skewed numerical features to log transform\n",
      "1stFlrSF          1.257286\n",
      "2ndFlrSF          0.861556\n",
      "3SsnPorch        11.372080\n",
      "BsmtCond         -3.602661\n",
      "BsmtExposure      1.119066\n",
      "BsmtFinSF1        0.980645\n",
      "BsmtFinSF2        4.144503\n",
      "BsmtFinType2      3.150951\n",
      "BsmtHalfBath      3.929996\n",
      "BsmtQual         -1.271611\n",
      "BsmtUnfSF         0.919688\n",
      "CentralAir       -3.457555\n",
      "EnclosedPorch     4.002344\n",
      "ExterCond         1.315069\n",
      "ExterQual         0.783456\n",
      "Fence             1.753731\n",
      "Fireplaces        0.725278\n",
      "Functional       -4.961675\n",
      "GarageCond       -3.381673\n",
      "GarageQual       -3.262260\n",
      "GarageYrBlt      -3.904632\n",
      "GrLivArea         1.068750\n",
      "KitchenAbvGr      4.300550\n",
      "LandSlope        -4.973254\n",
      "LotArea          13.109495\n",
      "LotFrontage       1.103039\n",
      "LotShape         -1.247973\n",
      "LowQualFinSF     12.084539\n",
      "MasVnrArea        2.621719\n",
      "MiscVal          21.939672\n",
      "OpenPorchSF       2.529358\n",
      "PavedDrive       -2.977741\n",
      "PoolArea         17.688664\n",
      "PoolQC           20.341424\n",
      "ScreenPorch       3.945101\n",
      "Street          -15.494756\n",
      "TotRmsAbvGrd      0.749232\n",
      "WoodDeckSF        1.844792\n",
      "TotLivArea        1.009157\n",
      "AvgRoomSize       0.931704\n",
      "Overallscore      1.907677\n",
      "ExterGrade        0.782428\n",
      "AllPorchSF        2.244500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "skewness = df[numerical_features].apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 0.7]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5       320\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        0\n",
       "13        0\n",
       "14        0\n",
       "15        0\n",
       "16        0\n",
       "17        0\n",
       "18        0\n",
       "19        0\n",
       "20        0\n",
       "21        0\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "29        0\n",
       "       ... \n",
       "1429      0\n",
       "1430      0\n",
       "1431      0\n",
       "1432      0\n",
       "1433      0\n",
       "1434      0\n",
       "1435      0\n",
       "1436      0\n",
       "1437      0\n",
       "1438      0\n",
       "1439      0\n",
       "1440      0\n",
       "1441      0\n",
       "1442      0\n",
       "1443      0\n",
       "1444      0\n",
       "1445      0\n",
       "1446      0\n",
       "1447      0\n",
       "1448      0\n",
       "1449      0\n",
       "1450      0\n",
       "1451      0\n",
       "1452      0\n",
       "1453      0\n",
       "1454      0\n",
       "1455      0\n",
       "1456      0\n",
       "1457      0\n",
       "1458      0\n",
       "Name: 3SsnPorch, Length: 2917, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness['3SsnPorch']\n",
    "df['3SsnPorch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.001\n",
    "skew_list = ['3SsnPorch', 'LotArea', 'LowQualFinSF', 'MiscVal', 'PoolArea', \n",
    "             'PoolQC', 'Street']\n",
    "\n",
    "for x in skew_list:\n",
    "    df[x] = boxcox1p(df[x], lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3720799331 Skewness BERFORE transformation\n",
      "2.51860869502 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "##3SsnPorch\n",
    "from scipy.special import boxcox1p\n",
    "lam = 0.001\n",
    "print(str(skewness['3SsnPorch']) + \" Skewness BERFORE transformation\")\n",
    "x = boxcox1p(skewness['3SsnPorch'], lam)\n",
    "print(str(x) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1094946932 Skewness BERFORE transformation\n",
      "2.6503539479 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "##LotArea\n",
    "lam = 0.001\n",
    "print(str(skewness['LotArea']) + \" Skewness BERFORE transformation\")\n",
    "xx = boxcox1p(skewness['LotArea'], lam)\n",
    "print(str(xx) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0845387954 Skewness BERFORE transformation\n",
      "2.57474025363 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "#LowQualFinSF\n",
    "lam = 0.001\n",
    "print(str(skewness['LowQualFinSF']) + \" Skewness BERFORE transformation\")\n",
    "xxx = boxcox1p(skewness['LowQualFinSF'], lam)\n",
    "print(str(xxx) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.9396721704 Skewness BERFORE transformation\n",
      "3.13778038004 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "#MiscVal\n",
    "lam = 0.001\n",
    "print(str(skewness['MiscVal']) + \" Skewness BERFORE transformation\")\n",
    "y = boxcox1p(skewness['MiscVal'], lam)\n",
    "print(str(y) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.688664487 Skewness BERFORE transformation\n",
      "2.93220769877 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "#PoolArea\n",
    "lam = 0.001\n",
    "print(str(skewness['PoolArea']) + \" Skewness BERFORE transformation\")\n",
    "yy = boxcox1p(skewness['PoolArea'], lam)\n",
    "print(str(yy) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3414240859 Skewness BERFORE transformation\n",
      "3.0653385481 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "#PoolQC  \n",
    "lam = 0.001\n",
    "print(str(skewness['PoolQC']) + \" Skewness BERFORE transformation\")\n",
    "yyy = boxcox1p(skewness['PoolQC'], lam)\n",
    "print(str(yyy) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.4947560207 Skewness BERFORE transformation\n",
      "nan Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "#Street\n",
    "lam = 0.001\n",
    "print(str(skewness['Street']) + \" Skewness BERFORE transformation\")\n",
    "a = boxcox1p(skewness['Street'], lam)\n",
    "print(str(a) + \" Skewnes AFTER transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.94510122562 Skewness BERFORE transformation\n",
      "1.59967555323 Skewnes AFTER transformation\n"
     ]
    }
   ],
   "source": [
    "#ScreenPorch\n",
    "lam = 0.001\n",
    "print(str(skewness['ScreenPorch']) + \" Skewness BERFORE transformation\")\n",
    "yyy = boxcox1p(skewness['ScreenPorch'], lam)\n",
    "print(str(yyy) + \" Skewnes AFTER transformation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
